'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/defenses/design-protections/','title':"Application Design",'section':"Defense Mechanisms",'content':"Application Design #  This section contains articles explaining how you can:\n Defend against cache probing attacks, see Cache Protections. Protect especially sensitive endpoints, see Subresource Protections.  "});index.add({'id':1,'href':'/docs/attacks/timing-attacks/clocks/','title':"Clocks",'section':"Timing Attacks",'content':"We can distinguish two types of clocks - Explicit and Implicit. Explicit clocks are the ones developers use to get direct timing measurements and such mechanisms are offered explicitly by the browser. Implicit clocks on the other hand, utilise particular web features to create unintended clocks that allow measuring the relative passage of time.\nExplicit Clocks #  performance.now API #  The performance.now() API allows developers to get high-resolution timing measurements.\nIn order to mitigate some XS-Leaks, performance.now()\u0026rsquo;s accuracy was reduced from a range of nanoseconds to a microsecond precision in all modern browsers 1 2 3.\n  Reduce resolution of performance.now (Webkit). link \u0026#x21a9;\u0026#xfe0e;\n Reduce precision of performance.now() to 20us (Gecko). link \u0026#x21a9;\u0026#xfe0e;\n Reduce resolution of performance.now to prevent timing attacks (Blink). link \u0026#x21a9;\u0026#xfe0e;\n    Since Firefox 79, this API can be used with full resolution in documents which do not share a browsing context group with cross-origin documents. This will require an application interested in this precision to explicitly opt-in to COOP and COEP.  Date API #  The Date API is the oldest API present in browsers to obtain timing measurements. It allows developers to get dates, and get Unix timestamps with Date.now(). These measurements are much less precise than performance.now(). Before the introduction of newer APIs attacks used to leverage this instead 1.\nImplicit Clocks #  SharedArrayBuffer and Web Workers #  With the introduction of Web Workers, new mechanisms to exchange data between threads were created 2. SharedArrayBuffer, one of those mechanisms, provides memory sharing between the main thread and a worker thread. Attackers can create an implicit clock by using two workers and a shared buffer. One worker runs in an infinite loop incrementing a number in the buffer. The other work can observe this number get incremented and use this to measure the relative passage of time.\n// -------- Main Thread clock creation -------- var buffer = new SharedArrayBuffer(16); var counter = new Worker(\u0026#34;counter.js\u0026#34;); counter.postMessage([buffer],[buffer]); var arr = new UintArray(buffer); relative_time = arr[0]; // -------- Web Worker counter.js -------- self.onmessage = function(event){ var[buffer] = event.data ; var arr = newUintArray(buffer); while(1){ arr[0]++; } } SharedArrayBuffer was removed from browsers with the publication of Spectre. It was reintroduced later in 2020 requiring documents to be in a secure context to make use of the API. Since secure contexts cannot reference any cross-origin content that has not explicitly opted in to being accessed, this means SharedArrayBuffers cannot be used as clocks for XS-Leaks.  Other Clocks #  There are a considerable number of APIs attackers can abuse to create implicit clocks: Broadcast Channel API, Message Channel API, requestAnimationFrame, setTimeout, CSS animations and others 3 4.\nReferences #    Exposing Private Information by Timing Web Applications, link \u0026#x21a9;\u0026#xfe0e;\n Shared memory: Side-channel information leaks, link \u0026#x21a9;\u0026#xfe0e;\n Fantastic Timers and Where to Find Them: High-Resolution Microarchitectural Attacks in JavaScript, link \u0026#x21a9;\u0026#xfe0e;\n Trusted Browsers for Uncertain Times, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':2,'href':'/docs/attacks/xs-search/','title':"XS-Search",'section':"Attacks",'content':"Cross-Site Search (XS-Search) is an important attack and principle in the family of XS-Leaks. The attack abuses Query-Based Search Systems to leak user information from an attacker origin 1 2. The original attack used timing measurements to detect whether or not a search system returned results and works as follows:\n Establish a baseline time for a request returning results (hit) and a baseline for a request with no results (miss). Start a timing attack on the request to the search endpoint, brute-forcing the first character (?q=r). If the measurement is under the hit baseline then add one more character (?q=ra); otherwise try a new one (?q=s). In the end, a full secret (?q=secret) can be leaked.  This attack requires multiple timing measurements to be accurate, something which can be improved with Inflation Techniques and statistical analysis. Furthermore, instead of brute-forcing letter by letter, attackers can search specific words or sentences to leak only the occurrence of results.\nThe most important part of this attack is its principle, as it can be applied in a different number of XS-Leaks.\nInflation Techniques #  The inflation techniques of XS-Search are used to increase the accuracy of the attack to make two responses easier to distinguish (hit or miss). These two mechanisms will allow attackers to make better measurements:\n If a search system reflects certain GET parameters into the response when returning results, it will increase the size of the response. This will make the request more distinguishable because the time to prepare the response and send it over the network will grow substantially. Force the server to perform more computation work before returning a response. This can be possible in search systems offering more expressive query languages (e.g exclude terms in Gmail will need to process every character in the results).  Extended Principle #  While the original research around XS-Search focused on timing attacks, the principle of the attack extends to other XS-Leaks. Instead of relying on timing measurements, which are unreliable, attackers can use other XS-Leaks to achieve the same observation.\nIn a Query-Based Search System, a user submits queries and gets responses associated with those queries. From this action, there are two different outcomes:\n The system shows results and the page will present a specific behavior (first state). The system does not show results and the page will present a different behavior from step 1 (second state).  If both behaviors above can be distinguished by a more reliable XS-Leak than timing, then an attacker could perform a more efficient XS-Search attack. For example, if the number of frames on a page varies based on search results (step 1 and 2 are distinguishable), this attack principle can be applied with a Frame Counting XS-Leak which could be more accurate than one using timing measurements.\nDefense #     Attack Alternative Same-Site Cookies Fetch Metadata COOP Framing Protections     XS-Search (Timing) ✔️ ✔️ ❌ ❌    References #    Cross-Site Search Attacks, link \u0026#x21a9;\u0026#xfe0e;\n Cross-Site Search (XS-Search) Attacks - Hemi Leibowitz, OWASP AppSec IL 2015, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':4,'href':'/docs/defenses/opt-in/','title':"Opt-In Mechanisms",'section':"Defense Mechanisms",'content':"Opt-In Mechanisms #  There are lots of different opt-in mechanisms that applications can deploy to defend against XS-Leaks. Note that many mechanisms can overlap in terms of what techniques they can defend against.\n Fetch Metadata allows the server to determine how and why a request was initiated so that it can choose to reject any malicious requests. Cross-Origin-Opener-Policy allows an application to prevent other websites from interacting with it via window.open or window.opener Cross-Origin-Resource-Policy allows an application to prevent other sites from including specific resources Framing Protections allow an application to define what sites are allowed to frame it Same-Site Cookies allow an application to change which requests from third party sites include cookies  "});index.add({'id':5,'href':'/docs/attacks/browser-features/corb/','title':"CORB Leaks",'section':"Browser Features",'content':"Cross-Origin Read Blocking (CORB) is a web platform security feature aimed at reducing the impact of speculative side-channel attacks such as Spectre. Unfortunately, blocking certain types of requests introduced a new type of XS-Leaks that allows attackers to detect if CORB was enforced on one request, but wasn\u0026rsquo;t on another. Nevertheless, the introduced XS-Leaks are much less problematic than the issues actively protected by CORB (e.g Spectre).\nCORB \u0026amp; Error Events #  Attackers can observe when CORB is enforced if a response returns a CORB protected Content-Type (and nosniff) with status code 2xx which results in CORB stripping the body and headers from the response. Detecting this protection will allow an attacker to leak the combination of both the status code (success vs. error) and the Content-Type (protected by CORB or not). This allows the distinction of two possible states:\n One state results in a request being protected by CORB and the second a client error (404). One state is protected by CORB and the second is not.  The following steps could be observed to abuse this protection with the first example:\n An attacker can embed a cross-origin resource in a script tag which returns 200 OK with text/html as Content-Type and a nosniff Header. To protect sensitive contents from entering the attacker\u0026rsquo;s process, CORB will replace the original response with an empty one. Since an empty response is valid JavaScript, the onerror event won\u0026rsquo;t be fired and onload will fire instead. The attacker triggers a second request (corresponding to a second state), similar to 1., which returns something other than 200 OK. The onerror event will fire.  The interesting behavior is that CORB creates a valid resource out of request which could contain something other than JavaScript (causing an error). Considering a non-CORB environment, both 1. and 4. requests would trigger an error. This introduces an XS-Leak as these situations are now distinguishable.\nDetect nosniff Header #  CORB could also allow attackers to detect when the nosniff header is present in the request. This problem originated due to the fact CORB is only enforced depending on the presence of this header and some sniffing algorithms. The example below shows two distinguishable states:\n CORB will prevent an attacker page which embeds a resource as a script if the resource is served with text/html as Content-Type along with the nosniff header. If the resource does not set nosniff and CORB fails to infer the Content-Type of the page (which remains text/html), a SyntaxError will be fired since the contents can\u0026rsquo;t be parsed as valid JavaScript. This error can be caught by listening to window.onerror as script tags only trigger error events in certain conditions.  Defense #     Same-Site Cookies Fetch Metadata COOP Framing Protections     ✔️ ✔️ ❌ ❌    This issue is known by Chromium, and while it might remain unfixed, its impact is highly reduced by the rollout of Same-Site Cookies by default in Chromium-based browsers.  Developers can deploy CORP in application resources to force a protection similar to CORB that does not inspect responses to decide when to act. To prevent attackers from abusing this XS-Leak, generic XS-Leaks defense mechanisms are also effective.  References #  "});index.add({'id':6,'href':'/docs/attacks/browser-features/corp/','title':"CORP Leaks",'section':"Browser Features",'content':"Explanation #  Cross-Origin Resource Policy (CORP) is a web platform security feature that allows websites to prevent certain resources from being loaded by other origins. This protection complements CORB since it is an opt-in defense whereas CORB blocks some cross-origin reads by default. Unfortunately, similarly to CORB applications can introduce a new XS-Leak if they misconfigure the use of this protection.\nA webpage will introduce an XS-Leak if CORP is enforced based on user data. If a page search feature enforces CORP when showing results, but doesn\u0026rsquo;t when returning no results, an attacker will be able to distinguish the two scenarios. This occurs because a page/resource protected by CORP will return an error when fetched cross-origin.\nDefense #  An application can avoid this XS-Leak if it guarantees CORP is deployed in all application resources/endpoints. Moreover generic security mechanisms that allow the invalidation of cross-site requests will also help prevent this attack.\n   Same-Site Cookies Fetch Metadata COOP Framing Protections     ✔️ ✔️ ❌ ❌    "});index.add({'id':7,'href':'/docs/attacks/error-events/','title':"Error Events",'section':"Attacks",'content':"When a webpage issues a request to a server (e.g fetch, HTML tags), this request will be received and processed by that server. When received the server will decide whether the request should succeed (e.g 200) or fail (e.g 404) based on the provided context. When a response has an error status an error event will be fired by the browser for the page to handle. These errors are also extended to situations where the parser fails, for example, trying to embed HTML content as an image.\nFor example, attackers can detect whether a user is logged into a service by checking if the user has access to resources only available to authenticated users 1. The impact of this XS-Leak varies depending on the application but it can lead to sophisticated attacks with the ability to deanonymize users 2.\nError events can be thrown from a large variety of HTML tags, and some behaviors vary from browser to browser 3   \\(^{p. 6}\\)  . For instance, they depend on the loaded resources, HTML tags, presence of certain headers (e.g nosniff, Content-Type) or enforcement of default browser protections, etc.\nThe principle of leaking information with error events can be abstracted and applied to a variety of XS-Leaks. For example one technique for Cache Probing uses Error Events to detect if a certain image was cached by the browser.\nCode snippet #  The below snippet demonstrates how an Error Event can be detected with the \u0026lt;script\u0026gt; tag.\nfunction probeError(url) { let script = document.createElement(\u0026#39;script\u0026#39;); script.src = url; script.onload = () =\u0026gt; console.log(\u0026#39;Onload event triggered\u0026#39;); script.onerror = () =\u0026gt; console.log(\u0026#39;Error event triggered\u0026#39;); document.head.appendChild(script); } // because google.com/404 returns HTTP 404, the script triggers error event probeError(\u0026#39;https://google.com/404\u0026#39;); // because google.com returns HTTP 200, the script triggers onload event probeError(\u0026#39;https://google.com/\u0026#39;); Defense #  The mitigation of this XS-Leak often varies on how applications handle certain resources and ends in the adoption of consistent behaviors as much as possible. In specific scenarios, applications might use Subresource Protections to prevent attackers from predicting an URL and go forward with an attack.\nFinally, without applying bigger changes in the logic of applications, generic web platform security features could be deployed to mitigate this XS-Leak at a larger scale.\n   Same-Site Cookies Fetch Metadata COOP Framing Protections     ✔️ \\(^{🔗}\\)   ✔️ ❌ ✔️ \\(^{🔗}\\)      🔗 - Defense mechanisms must be combined to be effective against different scenarios.\nReal World Example #   A bug abused a Twitter API endpoint where only a specified user would have access to it. This endpoint would return an error to every Twitter user except the owner. An attacker could exploit this behavior to deanonymize a user 1. Similarly, another bug abused an image authentication mechanism of private messages to achieve the same goal 4 2.  References #    Twitter ID exposure via error-based side-channel attack, link \u0026#x21a9;\u0026#xfe0e;\n Leaky Images: Targeted Privacy Attacks in the Web, link \u0026#x21a9;\u0026#xfe0e;\n Cross-Origin State Inference (COSI) Attacks: Leaking Web Site States through XS-Leaks, link \u0026#x21a9;\u0026#xfe0e;\n Tracking of users on third-party websites using the Twitter cookie, due to a flaw in authenticating image requests, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':8,'href':'/docs/attacks/frame-counting/','title':"Frame Counting",'section':"Attacks",'content':"Window references allow cross-origin pages to get access to some attributes of other pages. These references become available when using or allowing iframe and window.open. They provide some information (although limited) about the window as they still respect the Same Origin Policy.\nOne of the accessible attributes is window.length which provides the number of frames in the window. This attribute can give valuable information about a page to an attacker.\nWebsites commonly use frames (or iframes) and this choice doesn\u0026rsquo;t necessarily imply security issues. There are however cases where a website might change the number of frames in a page depending on some user information. This could happen for example on a page that changes layout depending on the GET parameters and the victim data. It might be possible for an attacker to infer information about the victim by measuring the value of window.length on different pages.\nCode snippet #  The below snippet demonstrates how to access the information about the number of frames on a cross-site page.\n// Get a reference to the window var win = window.open(\u0026#39;https://example.org\u0026#39;); // Wait for the page to load setTimeout(() =\u0026gt; { // Read the number of iframes loaded  console.log(\u0026#34;%d iframes detected\u0026#34;, win.length); }, 2000); Attack alternatives #  In some cases, different application states have the same number of frames, preventing attackers from being able to distinguish them. However, continuously recording the frame count while the page is loading may show a pattern that might leak information to the attacker.\n// Get a reference to the window var win = window.open(\u0026#34;https://example.org\u0026#34;); var pattern = []; // In a loop, register the number of iframes at 60ms interval var recorder = setInterval(() =\u0026gt; { pattern.push(win.length) }, 60); // Break the loop after 6 seconds setTimeout(() =\u0026gt; { clearInterval(recorder); console.log(\u0026#34;The pattern is: %s\u0026#34;, pattern.join(\u0026#39;, \u0026#39;)); }, 6 * 1000); Case Scenarios #   A website lets a user search for user information in a search engine, if the page structure has a different number of iframes depending on whether there are results to the user query, an attacker could use the XS-Search technique to leak those secrets. A website structures the user profile page differently based on gender or other PII. An attacker can easily leak this information by just opening the page and counting frames.  Defense #     Attack Alternative Same-Site Cookies Fetch Metadata COOP Framing Protections     iframe ✔️ ✔️ ❌ ✔️   window.open ✔️ (if Strict) ✔️ ✔️ ❌    Real World Example #  A Vulnerability reported to Facebook used this technique to leak user-related information such as specific contents published in posts, religious information about friends, or photo locations1.\nReferences #    Patched Facebook Vulnerability Could Have Exposed Private Information About You and Your Friends. link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':9,'href':'/docs/attacks/navigations/','title':"Navigations",'section':"Attacks",'content':"Detecting if a cross-site page triggered a navigation (or didn\u0026rsquo;t) can be useful to an attacker. For example, a website may trigger a navigation in a certain endpoint depending on the status of the user.\nTo detect if any kind of navigation occurred, an attacker can:\n Use an iframe and count the number of times the onload event is triggered. Check the value of history.length, accessible through any window reference. This gives the number of entries in the history of a victim either changed by history.pushState or regular navigations. To get the value of history.length an attacker changes the location of the window reference with the target website, changes back to same-origin, and finally reads the value.  Download Trigger #  When an endpoint sets the Content-Disposition: attachment header, it instructs the browser to download the response as an attachment instead of navigating to it. Detecting if this behavior occurred might allow attackers to leak private information if the outcome depends on the state of the victim\u0026rsquo;s account.\nDownload bar #  In Chromium-based browsers when a file is downloaded, a preview of the download process appears in a bar at the bottom, integrated into the browser window. By monitoring the window height attackers could detect whether the \u0026ldquo;download bar\u0026rdquo; opened.\n// Read the current height of the window var screenHeight = window.innerHeight; // Load the page that may or may not trigger the download window.open(\u0026#39;https://example.org\u0026#39;); // Wait for the tab to load setTimeout(() =\u0026gt; { // If the download bar appears, the height of all tabs will be smaller  if (window.innerHeight \u0026lt; screenHeight) { console.log(\u0026#39;Download bar detected\u0026#39;); } else { console.log(\u0026#39;Download bar not detected\u0026#39;); } }, 2000); This attack is only possible in Chromium-based browsers with automatic downloads enabled. The attack can\u0026rsquo;t be also repeated since the user needs to close the download bar for it to be measurable again.  Download Navigation (with iframes) #  Another way to test for the Content-Disposition: attachment header is to check if a navigation occurred. If a page load causes a download, it will not trigger a navigation and the window will stay within the same origin.\nThe following snippet can be used to detect whether such a navigation has occurred and therefore detect a download attempt.\n// Set the destination URL to test for the download attempt var url = \u0026#39;https://example.org/\u0026#39;; // Create an outer iframe to measure onload event var iframe = document.createElement(\u0026#39;iframe\u0026#39;); document.body.appendChild(iframe); // Create an inner iframe to test for the download attempt iframe.srcdoc = `\u0026lt;iframe src=\u0026#34;${url}\u0026#34; \u0026gt;\u0026lt;/iframe\u0026gt;`; iframe.onload = () =\u0026gt; { try { // If a navigation occurs, the iframe will be cross-origin,  // so accessing \u0026#34;inner.origin\u0026#34; will throw an exception  iframe.contentWindow.frames[0].origin; console.log(\u0026#39;Download attempt detected\u0026#39;); } catch(e) { console.log(\u0026#39;No download attempt detected\u0026#39;); } } When there is no navigation inside an iframe caused by a download attempt the iframe will not trigger an onload event directly. Because of that, in the example above, an outer iframe was used instead, that listens for onload event which triggers when subresources finished loading, including iframes.  This attack will work regardless of any Framing Protections, because the X-Frame-Options and Content-Security-Policy headers are ignored if Content-Disposition: attachment is specified.  Download Navigation (without iframes) #  A variation of the technique presented in the previous section can also be effectively tested using window objects.\n// Set the destination URL var url = \u0026#39;https://example.org\u0026#39;; // Get a window reference var win = window.open(url); // Wait for the window to load. setTimeout(() =\u0026gt; { try { // If a navigation occurs, the iframe will be cross-origin,  // so accessing \u0026#34;win.origin\u0026#34; will throw an exception  win.origin; parent.console.log(\u0026#39;Download attempt detected\u0026#39;); } catch(e) { parent.console.log(\u0026#39;No download attempt detected\u0026#39;); } }, 2000); Server-Side Redirects #  Inflation #  A server-side redirect can be detected from a cross-origin page if the destination URL increases in size and contains an attacker controlled input (either in the form of a query string parameter or a path). The following technique relies on the fact that it is possible to induce an error in most web-servers by generating big requests parameters/paths. Since the redirect increases the size of the URL, it can be detected by sending exactly one character less than the server maximum capacity. That way if the size increases the server will respond with an error that can be detected from a cross-origin page (eg via Error Events).\nAn example of this attack can be seen here.  Cross-Origin Redirects #  CSP Violations #  Content-Security-Policy (CSP) is an in-depth defense mechanism against XSS and data injection attacks. When a CSP is violated, a SecurityPolicyViolationEvent is thrown. An attacker can set up a CSP which will trigger a Violation event every time a fetch follows an URL not set in the CSP directive. This will allow an attacker to detect if a redirect to another origin occurred 1 2.\nThe example below will trigger a SecurityPolicyViolationEvent if the website set in fetch API (line 6) redirects to a website different then target.page.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;!-- Set the Content-Security-Policy to only allow example.org --\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Security-Policy\u0026#34; content=\u0026#34;connect-src https://example.org\u0026#34;\u0026gt; \u0026lt;script\u0026gt; // Listen for a CSP violation event document.addEventListener(\u0026#39;securitypolicyviolation\u0026#39;, () =\u0026gt; { console.log(\u0026#34;Detected a redirect to somewhere other than example.org\u0026#34;); }); // Try to fetch example.org. If it redirects to anoter cross-site website // it will trigger a CSP violation event fetch(\u0026#39;https://example.org/might_redirect\u0026#39;, { mode: \u0026#39;no-cors\u0026#39;, credentials: \u0026#39;include\u0026#39; }); \u0026lt;/script\u0026gt;   Case Scenarios #   An online bank decides to redirect wealthy users to unmissable stock opportunities by triggering a navigation to a reserved space on the website when users are consulting the account balance. If this is only done to a specific group of users, it becomes possible for an attacker to leak the \u0026ldquo;client status\u0026rdquo; of the user.  Defense #     Attack Alternative Same-Site Cookies Fetch Metadata COOP Framing Protections     iframe ✔️ ✔️ ❌ ✔️   history.length (iframe) ✔️ ✔️ ❌ ✔️   history.length (window.open) ✔️ (if Strict) ✔️ ✔️ ❌   Download bar ✔️ ✔️ ✔️ ✔️   Download Navigation (w/ timeout) ✔️ (if Strict) ✔️ ❓ ✔️   Download Navigation (no timeout) ✔️ ✔️ ✔️ ✔️   CSP Violations ✔️ ✔️ ❌ ❌    Real-World Examples #   A vulnerability reported to Twitter used this technique to leak the contents of private tweets using XS-Search. This attack was possible because the page would only trigger a navigation depending on whether there were results to the user query 3.  References #    Disclose domain of redirect destination taking advantage of CSP, link \u0026#x21a9;\u0026#xfe0e;\n Using Content-Security-Policy for Evil, link \u0026#x21a9;\u0026#xfe0e;\n Protected tweets exposure through the url, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':10,'href':'/docs/attacks/timing-attacks/network-timing/','title':"Network Timing",'section':"Timing Attacks",'content':"Network Timing side-channels have been present on the web since its beginning 1 2. These attacks have had different levels of impact over time, gaining new attention when browsers started shipping high precision timers like performance.now().\nTo obtain timing measurements attackers must use a clock, either an implicit or explicit one. These clocks are usually interchangeable for the purposes of XS-Leaks and only vary in accuracy and availability. For simplicity, this article will assume use of the performance.now() API, an explicit clock present in all modern browsers.\nThis side-channel allows attackers to infer information from a cross-site request based on how much time it takes to complete that request 3. The network timing measurement may vary based on a user state and it\u0026rsquo;s usually connected to:\n The resource size. The computation time in the backend. The number and size of sub-resources. Cache status.  Learn more about the different types of clocks in the Clocks Article.  Modern Web Timing Attacks #  The performance.now() API can be used to measure how much time it takes to perform a request.\n// Start the clock var start = performance.now() // Measure how long it takes to complete the fetch requests fetch(\u0026#39;https://example.org\u0026#39;, { mode: \u0026#39;no-cors\u0026#39;, credentials: \u0026#39;include\u0026#39; }).then(() =\u0026gt; { // When fetch finishes, calculate the difference  var time = performance.now() - start; console.log(\u0026#34;The request took %d ms.\u0026#34;, time); }); Onload events #  A similar process can be used to measure how long it takes to fetch a resource by simply watching for an onload event.\n// Create a script element pointing to the page we want to time var script = document.createElement(\u0026#39;script\u0026#39;); script.src = \u0026#34;https://example.org\u0026#34;; document.body.appendChild(script); // Start the clock var start = performance.now(); // When script loads, caculate the time it took to finish the request script.onload = () =\u0026gt; { var time = performance.now() - start; console.log(\u0026#34;The request took %d ms.\u0026#34;, time) } A similar technique can be used for other HTML elements, e.g. \u0026lt;img\u0026gt;, \u0026lt;link\u0026gt;, \u0026lt;iframe\u0026gt; which could be used in scenarios where other techniques fail. For example, if Fetch Metadata blocked loading of a resource into a script tag it may allow it into an image tag.  Sandboxed Frame Timing Attacks #  If a page doesn\u0026rsquo;t have any Framing Protections implemented, an attacker can time how long it takes for the page and all subresources to load over the network. By default, the onload handler for an iframe will be invoked after all the resources have been loaded and all Javascript has finished executing. But, an attacker can eliminate the noise of script execution by including the sandbox attribute in the \u0026lt;iframe\u0026gt;. This attribute will block a lot of features including Javascript execution, which results in almost pure network measurement.\nvar iframe = document.createElement(\u0026#39;iframe\u0026#39;); // Set the URL of the destination website iframe.src = \u0026#34;https://example.org\u0026#34;; // Set sandbox attribute to block script execution iframe.sandbox = \u0026#34;\u0026#34;; document.body.appendChild(iframe); // Measure the time before the request was initiated var start = performance.now(); iframe.onload = () =\u0026gt; { // When iframe loads, calculate the time difference  var time = performance.now() - start; console.log(\u0026#34;The iframe and subresources took %d ms to load.\u0026#34;, time) } Cross-window Timing Attacks #  An attacker can also measure the network timing of a page by opening a new window with window.open and waiting for the window to start loading. The snippet below shows how to make this measurement.\n// Open a new window to measure when the iframe starts loading var win = window.open(\u0026#39;https://example.org\u0026#39;); // Measure the initial time var start = performance.now(); // Define the loop function measure(){ try{ // If the page has loaded, then it will be on a different origin  // so `win.origin` will throw an exception  win.origin; // If the window is still same-origin, immediately repeat the loop but  // without blocking the event loop  setTimeout(measure, 0); }catch(e){ // Once the window has loaded, calculate the time difference  var time = performance.now() - start; console.log(\u0026#39;It took %d ms to load the window\u0026#39;, time); } } // Initiate the loop that breaks when the window switches origins measure(); Note that this POC uses setTimeout in order to create the rough equivalent of a while(true) loop. It is necessary to implement this way in order to avoid blocking the JS event loop.  This technique can also be adapted to measure the Execution Timing of a page by making the event loop busy.  Timeless Timing Attacks #  Other attacks do not consider the notion of time to perform a timing attack 4. Timeless attacks consist of fitting two HTTP requests in a single packet, the baseline and the attacked request, to guarantee they arrive at the same time to the server. The server will process the requests concurrently, and return a response based on their execution time as soon as possible. One of the two requests will arrive first, allowing the attacker to get the timing difference by comparing the order in which the requests arrived.\nThe advantage of this technique is the independence on network jitter and uncertain delays, something that is always present in the remaining techniques.\nThe original research needs to be adapted to work in a browser since it handles all network-specific tasks.  This attack is limited to specific versions of HTTP and joint scenarios. It makes certain assumptions and has requirements regarding server behaviors.  Defense #     Attack Alternative Same-Site Cookies Fetch Metadata COOP Framing Protections     Modern Timing Attacks ✔️ ✔️ ❌ ❌   Frame Timing (Network) ✔️ ✔️ ❌ -   Frame Timing (Sandbox) ✔️ ✔️ ❌ -   Cross-window Timing ✔️ (if Strict) ✔️ ❌ ❌   Timeless Timing ✔️ ❓ ❌ ❌    References #    Exposing Private Information by Timing Web Applications, link \u0026#x21a9;\u0026#xfe0e;\n Cross-domain search timing, link \u0026#x21a9;\u0026#xfe0e;\n The Clock is Still Ticking: Timing Attacks in the Modern Web - Section 4.3.3, link \u0026#x21a9;\u0026#xfe0e;\n Timeless Timing Attacks: Exploiting Concurrency to Leak Secrets over Remote Connections, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':11,'href':'/docs/attacks/cache-probing/','title':"Cache Probing",'section':"Attacks",'content':"The principle of Cache Probing consists of detecting whether some resource was cached by the browser. The concept is known since the beginning of the web 1 and initially relied on detecting timing differences.\nWhen a user visits a website some resources such as images, scripts, and HTML content are fetched and later cached by the browser (under certain conditions). This optimization will make future navigations faster as the browser will serve those resources from disk instead of requesting them again. If an attacker can detect which resources are cached it may be enough to leak whether a user accessed a specific page in the past.\nA variation on cache probing abuses Error Events to perform more accurate and impactful attacks.\nAttack Principle #  An attacker wants to know whether a user visited a certain social network.\n A user visits a social network and some of the subresources will be cached. The user visits an attacker controlled page which will fetch a resource that is usually fetched by that social network. Using a Network Timing XS-Leak, the attacker page can detect the difference from a response coming from the cache (step 1 happened) or coming from the network (step 1 did not happen). The delay will be significantly lower in a request served from the cache.  Cache Probing with Error Events #  Cache Probing with Error Events 2 allows more accurate attacks. Instead of relying on timing measurements, this leverages Error Events and some server-side behavior to detect whether a resource was cached. The attack works as follows:\n Invalidate the resource from the browser cache. This step is required to make sure the attack will not consider a resource previously cached in another visit. Perform a request that will cause different items to be cached depending on the user\u0026rsquo;s state. For example, load a page that will include a specific image only if the user is logged in. This request can be triggered by navigating to the target website with \u0026lt;link rel=prerender.., embedding the website in an iframe, or opening a new window with window.open. Trigger a request that will cause the server to reject the request. For example, include an overlong referer header that will make the server reject the request. If the resource was cached in step 2, this request will succeed instead of triggering an error event.  Invalidate the cache #  To invalidate a resource from the cache the attacker must force the server to return an error when fetching that subresource. There are a couple of ways to achieve this:\n A request with an overlong referer header and 'cache':'reload'. This might not work as browsers capped the length of the referrer to prevent this. A POST request with a fetch no-cors. Sometimes even in cases where an error is not returned the browser invalidates the cache. Request headers such as Content-Type, Accept, Accept-Language, etc that may cause the server to fail (more application dependent). Other request properties.  Often some of these methods might be considered a bug in the browser (e.g. this bug).\nDefense #  Currently there are no good defense mechanisms that would allow websites to fully protect against Cache Probing attacks. Nonetheless, a website might mitigate the attack surface by deploying Cache Protections, such as:\n Cache-control header used to prevent the resource from caching. Random Tokens used to make the URLs unpredictable for attackers. Vary: Sec-Fetch-Site used to segregate the cache by a group of origins.  A promising defense against this attack is partitioning the HTTP cache by the requesting origin. This browser provided protection prevents an attacker\u0026rsquo;s origin from interfering with cached resources of other origins.\nAs of November 2020, Partitioned Caches are not available in most browsers, so applications cannot rely on them.  Real World Example #   An attacker using the Error Events Cache Probing could detect whether a user watched a specific YouTube Video by checking if the video thumbnail ended up in browser cache 3.  References #    Timing Attacks on Web Privacy, link \u0026#x21a9;\u0026#xfe0e;\n HTTP Cache Cross-Site Leaks, link \u0026#x21a9;\u0026#xfe0e;\n Mass XS-Search using Cache Attack, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':12,'href':'/docs/defenses/secure-defaults/','title':"Secure Defaults",'section':"Defense Mechanisms",'content':"Secure Defaults #  Partitioned Caches ensure that cache resources cannot be shared in between different sites. Cross Origin Read Blocking (CORB) prevents certain types of responses from being referenced by certain classes of requests.\n"});index.add({'id':13,'href':'/docs/attacks/timing-attacks/execution-timing/','title':"Execution Timing",'section':"Timing Attacks",'content':"Measuring the time of JavaScript execution in a browser can give attackers information on when certain events are triggered, and how long some operations take.\nTiming the Event Loop #  JavaScript\u0026rsquo;s concurrency model is based on a single-threaded event loop which means it can only run one task at a time. If, for example, some time-consuming task blocks the event loop, the user can perceive a freeze on a page as a result of the UI thread being starved. Other tasks must wait until the blocking one runs to conclusion. Each browser implements different process models, which means some web sites might run in different threads (and event loops) depending on their relations.\nSome techniques can exploit this model to steal secrets from a cross-origin page:\n Infer how long code from a different origin takes to run by measuring how long it takes to run next in the event pool 1 2. The attacker keeps sending events to the event loop with fixed properties, which will eventually be dispatched if the pool is empty. Other origins will dispatch events to the same pool, and this is where an attacker infers the timing difference by detecting if a delay occurred with one of its tasks. Steal a secret from a cross-origin page if the said secret is being compared by an attacker-controlled string. The leak is a result of comparing timing differences in the event loop of a char-by-char string comparison 2 (using the previous technique). In browsers without process isolation, cross-window communications between different origins will run in the same thread, thus sharing the same event loop.  This attack is no longer possible in Browsers with process isolation mechanisms in place. Such mechanisms are only present in Chromium-Based browsers with Site Isolation and soon in Firefox under Project Fission.  Busy Event Loop #  Another technique to measure JavaScript Execution consists of blocking the event loop of a thread and timing how long it takes for the event loop to become available again. One of the main advantages of this technique is its ability to circumvent Site Isolation as an attacker origin can mess with the execution of another origin. The attack works as follows:\n Navigate the target website in a separate window with window.open or inside an iframe (if Framing Protections are not in place). Wait for the long computation to start. Load any same-site page inside an iframe, regardless of any Framing Protections.  An attacker can detect how long the target website is executed by timing how long it took for the iframe (in step 3) to trigger the onload event (Network Timing of step 3 should be minimal). Since both navigations occurred within the same context and they are same-site, they run in the same thread and share the same event loop (they can block each other).\n// Open a new window to measure how long the window blocks the event loop // for the site example.org window.open(\u0026#39;https://example.org/expensive\u0026#39;); // TODO: Wait for the expensive window to load, e.g. via timeout // then create an iframe to the same site var ifr = document.createElement(\u0026#39;iframe\u0026#39;); ifr.src = \u0026#34;https://example.org\u0026#34;; document.body.appendChild(ifr); // Measure the initial time var start = performance.now(); ifr.onload = () =\u0026gt; { // When the iframe loads calculate the time difference  var time = performance.now() - start; console.log(\u0026#39;It took %d ms to load the window\u0026#39;, time); } Service Workers #  Service Workers can be used to offer offline solutions to web applications but they can be abused by attackers to measure the timing of javascript execution3. They serve as a proxy between the browser and the network and allow applications to intercept any network requests made by the main thread (document).\nTo make a timing measurement an attacker can perform the following steps:\n The attacker registers a service worker in one of its domains (attacker.com). In the main document, the attacker issues a navigation (window.open) to the target website and instructs the Service Worker to start a timer. When the new window starts loading the attacker will navigate the reference obtained in step 2 to a page handled by the service worker. When the request performed in step 3 arrives to the Service Worker it will return a 204 (No Content) response, which will abort the navigation. At this point the Service Worker will collect a measurement from the timer started in step 2. This measurement will be affected by how long JavaScript blocked the navigation for.  Since no navigation actually occurs, steps from 3 to 5 can be repeated to get more measurements on successive JavaScript execution timings.\nCSS Injections #  This group of XS-Leaks requires a CSS Injection on the target page.  Among the different CSS Injection vectors, the most noticeable one is the abuse of CSS Selectors. They can be used as an expression to match and select certain HTML elements. For example, the selector input[value^=\u0026quot;a\u0026quot;] will be matched if the value of an input tag starts with the character \u0026ldquo;a\u0026rdquo;. So, to detect if a CSS Selector matched the expression, attackers could trigger a callback to one of their websites using certain properties like background, @import, etc 4 5. The matching process can be easily brute-forced, and extended to the full string.\njQuery, CSS Selectors \u0026amp; Short-circuit Timing #  Attackers can abuse another interesting behavior of CSS selectors which is short-circuit evaluation of expressions. This expression is received in an URL hash and evaluated if the page executes jQuery(location.hash) 6.\nA timing attack is possible because the expression is compared from right to left, so if the selector main[id='site-main'] does not match and fails to evaluate, the other parts of the selector (*:has(*:has(*:has(*))))) which take longer to execute, are ignored (just like the and operator but backwards).\n$(\u0026#34;*:has(*:has(*:has(*)) *:has(*:has(*:has(*))) *:has(*:has(*:has(*)))) main[id=\u0026#39;site-main\u0026#39;]\u0026#34;) This attack is no longer possible in Browsers with process isolation mechanisms in place. Such mechanisms are only present in Chromium-Based browsers with Site Isolation and soon in Firefox under Project Fission.  In browsers with process isolation mechanisms, Service Workers can be abused to obtain the execution timing measurement or tricks like Busy Event Loop tricks to circumvent Site Isolation.  ReDoS #  This group of XS-Leaks requires an injection of Regex Expressions on the target page.  Regular Expression Denial of Service (ReDoS) is a technique which results in a Denial of Service in applications that allow Regex as user input 2 7. Maliciously crafted regular expressions can be made to run in exponential time. This can be used as an XS-Leak vector if a regex can be injected that has a different runtime depending on some data on the page. This could happen on the client-side or the server-side.\nDefense #     Attack Alternative Same-Site Cookies Fetch Metadata COOP Framing Protections     T. Event Loop ✔️ (if Strict) ✔️ ❓ ❌   Service Workers ✔️ ✔️ ✔️ ❌   jQuery ✔️ ✔️ ❌ ❌   ReDoS ✔️ ✔️ ❌ ❌   Busy Event Loop ✔️ ✔️ ❌ ❌    References #    Loophole: Timing Attacks on Shared Event Loops in Chrome, link \u0026#x21a9;\u0026#xfe0e;\n Matryoshka - Web Application Timing Attacks (or.. Timing Attacks against JavaScript Applications in Browsers), link \u0026#x21a9;\u0026#xfe0e;\n Security: XS-Search + XSS Auditor = Not Cool, link \u0026#x21a9;\u0026#xfe0e;\n CSS Injection Primitives, link \u0026#x21a9;\u0026#xfe0e;\n HTTPLeaks, link \u0026#x21a9;\u0026#xfe0e;\n A timing attack with CSS selectors and Javascript, link \u0026#x21a9;\u0026#xfe0e;\n A Rough Idea of Blind Regular Expression Injection Attack, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':14,'href':'/docs/attacks/timing-attacks/hybrid-timing/','title':"Hybrid Timing",'section':"Timing Attacks",'content':"Hybrid Timing Attacks allow attackers to measure the sum of a bunch of factors that influence the final timing measurement. These factors include:\n Network delays Document parsing Retrieval and processing of subresources Code execution  Some of the factors differ in value depending on the application. This means that Network Timing might be more significant in pages with more backend processing while Execution Timing can be more significant in applications processing and displaying data within the browser. Attackers can also eliminate some of these factors to obtain more precise measurements. For example, one could preload all the subresources by embedding the page as an iframe (forcing the browser to cache the subresources) and do a second measurement which will exclude any delay introduced by the retrieval of those subresources.\nFrame Timing Attacks (Hybrid) #  If a page does not set Framing Protections, an attacker can obtain a hybrid measurement that considers all the factors. This attack is similar to the Network-based Attack, but when the resource is retrieved the page is rendered and executed by the browser (subresources fetched and JavaScript executed). In this scenario, the onload event only triggers once the page fully loads (including subresources and script execution).\nvar iframe = document.createElement(\u0026#39;iframe\u0026#39;); // Set the URL of the destination website iframe.src = \u0026#34;https://example.org\u0026#34;; document.body.appendChild(iframe); // Measure the time before the request was initiated var start = performance.now(); iframe.onload = () =\u0026gt; { // When iframe loads, calculate the time difference  var time = performance.now() - start; console.log(\u0026#34;The iframe and subresources took %d ms to load.\u0026#34;, time) } Defense #     Attack Alternative Same-Site Cookies Fetch Metadata COOP Framing Protections     Frame Timing (Hybrid) ✔️ ✔️ ❌ ✔️    "});index.add({'id':15,'href':'/docs/attacks/id-attribute/','title':"ID Attribute",'section':"Attacks",'content':"The id attribute is widely used to identify some HTML elements. Unfortunately, cross-origin websites can determine whether a given id is set anywhere on the page by leveraging the focus event and URL fragments. If https://example.com/foo#bar is loaded, the browser will attempt to scroll to the element with id=\u0026quot;bar\u0026quot;. This can be detected cross-origin by loading https://example.com/foo#bar in an iframe and if there is an element with id=\u0026quot;bar\u0026quot; then the focus event will fire. The blur event can also be used for the same purpose 1.\nSome web applications set id attributes in focusable elements that may lead to user information disclosure. These ids can either be direct information related to the user (e.g. a secret) or information associated with a user state (e.g account status).\nCode snippet #  The below snippet presents an example way of detecting the ID attribute from another site.\n// Listen to onblur event onblur = () =\u0026gt; alert(\u0026#39;Focus was lost, so there was a focusable element with the specified ID\u0026#39;); var ifr = document.createElement(\u0026#39;iframe\u0026#39;); // If a page has a focusable element with id=\u0026#34;x\u0026#34; it will gain focus // E.g. \u0026lt;input id=\u0026#34;x\u0026#34; value=\u0026#34;test\u0026#34; /\u0026gt; ifr.src = \u0026#39;https://example.org/#x\u0026#39;; document.body.appendChild(ifr); The above technique doesn\u0026rsquo;t seem to work in Firefox.  Case Scenarios #   A bank allows its clients to generate short numeric One-Time PINs (OTP) in the browser application to authenticate sessions on mobile devices. The bank used the OTP as the id of a button that is used to show the PIN to the client. This technique could be used to steal these OTP codes by brute forcing every option and then using them to compromise user accounts. A web application uses a specific set of predefined ids and HTML elements when an account has a premium status or the user is of a certain gender. The attacker can detect whether a specific id is present on the victim\u0026rsquo;s page and leak the account information.  Defense #     Attack Alternative Same-Site Cookies Fetch Metadata COOP Framing Protections     iframe ✔️ ✔️ ❌ ✔️    References #    Leaking IDs using focus, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':16,'href':'/docs/attacks/postmessage-broadcasts/','title':"postMessage Broadcasts",'section':"Attacks",'content':"Applications often use postMessage broadcasts to share information with other origins. postMessage can lead to two kinds of XS-Leaks:\n  Sensitive messages shared with untrusted origins\n The postMessage API supports a targetOrigin parameter that can be used to restrict which origins can receive the message. If the message contains any sensitive data, it is important to use this parameter.    Leaking information based on different content or on the presence of a broadcast\n Similar to other XS-Leak techniques, this could be used to form an oracle. For example, if an application sent out a postMessage broadcast saying \u0026ldquo;Page Loaded\u0026rdquo; only if a user existed with a given username, this could be used to leak information.    Defense #  There is no clear solution to mitigate this XS-Leak as it depends deeply on the purpose of doing a postMessage broadcast. Applications should limit postMessage communications to a group of known origins and when this is not possible they should have the same behavior even when in different states to prevent attackers from inferring any differences.\nReferences #  "});index.add({'id':19,'href':'/docs/attacks/experiments/','title':"Experiments",'section':"Attacks",'content':"Experiments #  This section presents XS-Leaks that affect experimental features. These features are usually hidden under a browser preference flag and its corresponding specification under active discussion. It\u0026rsquo;s important to refer these features and follow their development since the early stages to prevent XS-Leaks from happening.\n"});index.add({'id':20,'href':'/docs/attacks/historical/','title':"Historical",'section':"Attacks",'content':"Historical Attacks #  The articles in this section present XS-Leaks that were addressed within the browser and don\u0026rsquo;t work anymore. Some of the mitigations consist of:\n Reduce the accuracy of some powerful APIs. Add noise to a certain measurement to prevent any malicious inference from it. Deprecate and remove features and APIs. Change feature behavior.  "});index.add({'id':21,'href':'/docs/defenses/','title':"Defense Mechanisms",'section':"Docs",'content':"Defense Mechanisms #  Defending against all possible XS-Leaks Attack Vectors is not a trivial task. Each one of the attack vectors affects different web and browser components and has its quirks. Some bug bounty programs, such as Google VRP, even stopped paying for new XS-Leaks reports as they are focusing on large systemic changes to defend against XS-Leaks 1. Google and many other companies believe that the right approach to fixing XS-Leaks is to invest time and engineering power into new large scale mitigations and changes to the web platform that applications can use to mitigate entire categories of XS-Leaks.\nBrowsers now provide a number of useful opt-in mechanisms that can be used to mitigate XS-Leaks. While these provide strong protections, the disadvantage is that they are not yet well supported by every browser. Defending against XS-Leaks effectively requires a mixture of different techniques, each of which is described in detail below.\nApplication Design #  Application design techniques are focused on carefully designing the application in a way that prevents XS-Leaks. This is a very useful approach when it is not practical to enable stronger global protections immediately. The other big advantage is that careful application design can stop XS-Leaks even on older browsers that don\u0026rsquo;t support the newest browser standards.\nIt is very difficult to use application design techniques to block every XS-Leak technique across an entire application. While application design techniques are effective at stopping severe leaks, opt-in mechanisms provided by the browser are a better overall solution.  Opt-in Mechanisms #  These defense mechanisms allow applications to address classes of similar XS-Leaks at the same time. These protections can either allow applications to change the behavior of the browser or provide additional information that applications can use to change their own behavior.\nDeploying a combination of opt-in defense mechanisms should be the default strategy. Not only do they protect against XS-Leaks, but also against other vulnerabilities such as XSSI, Clickjacking, CSRF, etc.  When using any mitigations that rely on browser support, be sure to check that they are well supported by your customers' browsers. For example, fetch metadata headers are a great tool, but are currently only supported in Chromium-based browsers. Check MDN for up-to-date information on browser support for different standards.  Secure Defaults #  Browser vendors are actively working on changing default behaviors to help mitigate some of the XS-Leaks mentioned in this wiki. Changing default behaviors is a balancing act between improving security and preserving backwards compatibility.\nSecure defaults are amazing! They can help protect applications and users without any additional effort from developers. But note that they\u0026rsquo;re unlikely to completely prevent XS-Leaks.  References #    Google Bughunter University - XSLeaks and XS-Search, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':22,'href':'/docs/defenses/design-protections/cache-protections/','title':"Cache Protections",'section':"Application Design",'content':"There are a number of different approaches applications can use to defend against cache probing-based XS-Leaks. These approaches are explained in the following sections.\nCache Protection via Cache-Control Headers #  If it is acceptable to disable caching, doing so provides a strong defense against cache probing attacks. Disabling caching means that every time someone loads a resource, the resource has to be fetched again. To disable caching, set a Cache-Control: no-store header on every single response that you wish to protect.\nAdvantages:\n Supported by all major browsers  Disadvantages:\n Negatively impacts site performance  Cache Protection via Random Tokens #  Rather than disabling caching, applications can include additional data in URLs in order to defend against cache probing attacks. This can be achieved by including a random token in the URL of every subresource that you reference. If an attacker cannot guess this random token, then the attacker cannot determine whether items are in the cache via any straightforward techniques.\nSuppose that every page on your application loads the user\u0026rsquo;s profile photo: /user/\u0026lt;USERNAME\u0026gt;.png. An attacker could check which user is signed in by probing the cache for /user/john.png, /user/jane.png, and so on.\nThis is where a random token can come into play. If implemented, the application takes the user\u0026rsquo;s profile photo from /user/\u0026lt;USERNAME\u0026gt;.png?cache_buster=\u0026lt;RANDOM_TOKEN\u0026gt; on every load. The server does not need to do anything with this random token. It is there purely to ensure that there is no way for an attacker to probe the cache without knowing the random token.\n If implemented carefully, an application could even have a user-specific random token that is reused across page loads. This would allow subresources to still be cached since the URL would remain constant for a given user.\nAdvantages:\n Supported by every major browser Does not break caching  Disadvantages:\n Difficult to implement  Cache Protection via Fetch Metadata #  Fetch-Metadata is meant to allow servers to determine how and why a request was initiated on the client side. One piece of information that is exposed is the Sec-Fetch-Site header which specifies whether a request is coming from the same origin or a different origin. This can be combined with the Vary header in order to force the browser to segment the cache based on whether a request is made from the same origin or a different origin.\nThis is done by setting Vary: Sec-Fetch-Site on all resources you wish to protect.\nAssume we have the resource cdn.example.com/image.png that we wish to protect from cache probing attacks. If we set Vary: Sec-Fetch-Site on it, this leads to the following behavior:\n If example.com tries to load the resource, the request is initiated by the same site so it is cached under (SFS: same-site, resource_url) If cdn.example.com tries to load the resource, the request is initiated by the same origin so it is cached under (SFS: same-origin, resource_url) If evil.com tries to load the resource, the request is initiated by a different site so it is cached under (SFS: cross-site, resource_url)  Note that this means cross-site requests are separated from same-site and same-origin requests.\n Advantages:\n Does not break caching  Disadvantages:\n Fetch metadata is a new standard that is currently only supported in Chromium-based browsers (e.g. Chrome and Edge) Cross-site subresources loaded on the page are not protected (e.g. subresources from CDNs) If third parties load the resource, they are not protected  "});index.add({'id':24,'href':'/docs/attacks/timing-attacks/connection-pool/','title':"Connection Pool",'section':"Timing Attacks",'content':"Another way to measure the network timing of a request consists of abusing the socket pool of a browser 1. Browsers use sockets to communicate with servers and since the Operating System and the hardware it runs on have limited resources, browsers have to impose a limit.\nTo exploit the existence of this limit attackers can:\n Check what is the limit of the browser, for example 256 global sockets. Block   \\(255\\)  sockets for a long period of time by performing  \\(255\\)  requests to different hosts that simply hang the connection Use the  \\(256^{th}\\)  socket by performing a request to the target page. Perform a  \\(257^{th}\\)  request to another host. Since all the sockets are being used (in steps 2 and 3), this request must wait until the pool gets an available socket. This waiting period will give the attacker the network timing of the  \\(256^{th}\\)  socket, which belongs to the target page. This occurs because the  \\(255\\)  sockets in step 2. are still blocked, so if the pool got an available socket it was caused by the release of the socket in step 3. The time to release the  \\(256^{th}\\)  socket is directly connected with the time taken to complete the request.  Defense #     Same-Site Cookies Fetch Metadata COOP Framing Protections     ✔️ (if Strict) ✔️ ❌ ❌    Similarly to partitioned caches some browsers are considering to extend the principle of \u0026ldquo;split per site/origin\u0026rdquo; of resources to socket pools.  References #    Leak cross-window request timing by exhausting connection pool, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':25,'href':'/docs/attacks/historical/content-type/','title':"Content-Type",'section':"Historical",'content':"Leaking the Content-Type of a request could offer an attacker a new way to distinguish two requests from each other.\ntypeMustMatch #  typeMustMatch is a boolean that reflects the typeMustMatch attribute of the object element. It ensures a certain MIME type must be enforced when loading an object verifying if the Content-Type of the resource is the same as the one provided in the object. Unfortunately, this enforcement would allow attackers to leak the Content-Type and Status Codes returned by a website 1\nRoot Cause #  Considering the snippet below, not_loaded would be rendered if the returned Content-Type of https://target/api did not match the one in type, or the server returned a status different than 200.\n\u0026lt;object type=\u0026#34;application/json\u0026#34; data=\u0026#34;https://example.org\u0026#34; typemustmatch\u0026gt; not_loaded \u0026lt;/object\u0026gt; Issues #  An attacker could leak the Content-Type and Status Codes of a website by detecting whether the object rendered, which will happen when all the conditions are met. The attacker could check the values of clientHeight and clientWidth which will likely be different than 0 when the object renderendersrers (and returns status 200). Since typeMustMatch requires the server to return status 200 to load a resource, it would be possible to detect error pages, similarly to Error Events XS-Leaks.\nThe example below shows how this behavior could be detected by embedding an object inside an iframe and checking the values of clientHeight and clientWidth when the iframe triggers the onload event.\n// Set the destination URL var url = \u0026#39;https://example.org\u0026#39;; // The content type we want to check for var mime = \u0026#39;application/json\u0026#39;; var ifr = document.createElement(\u0026#39;iframe\u0026#39;); // Load an object inside iframe since object does not trigger onload event ifr.srcdoc = ` \u0026lt;object id=\u0026#34;obj\u0026#34; type=\u0026#34;${mime}\u0026#34; data=\u0026#34;${url}\u0026#34; typemustmatch\u0026gt; error \u0026lt;/object\u0026gt;`; document.body.appendChild(ifr); // When the iframe loads, read the height of the object. If it is the height // of a single line of text, then the content type of the resource was not // `application/json`. If it is a different height, then it was `application/json`. ifr.onload = () =\u0026gt; { console.log(ifr.contentWindow.obj.clientHeight) }; Fix #  Firefox was the only browser supporting the typeMustMatch attribute 2 and since no other browsers offered support, it was removed in version 68 and from the HTML Living Standard.\nReferences #    Cross-Site Content and Status Types Leakage, link \u0026#x21a9;\u0026#xfe0e;\n Remove support for typemustmatch, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':26,'href':'/docs/defenses/secure-defaults/corb/','title':"Cross-Origin Read Blocking",'section':"Secure Defaults",'content':"Cross-Origin Read Blocking (CORB) is a security mechanism that prevents attackers from loading certain cross-origin resources 1. This protection was created to defend against speculative side-channel attacks such as Spectre that allow attackers to read the memory of their own process. CORB aims to prevent attackers from loading certain sensitive cross-origin resources into an attacker controlled process. For example, if the attacker tries to load cross-origin HTML, XML, or JSON into an img tag, CORB will prevent this from happening. With CORB, it will be treated as though the server returned no data.\nCORB is important for defending against XS-Leaks, especially Spectre-like attacks.\nTo classify resources, CORB uses the Content-Type header, the nosniff header, and a variety of other heuristics.\nCross-Origin Resource Policy (CORP) is an opt-in protection which enforces and extends CORB.  Currently, only Chromium-based browsers support CORB.  CORB does not protect against navigational requests. This means that in browsers that do not support out-of-process iframes, a CORB protected resource may still end up in another origin\u0026rsquo;s process if framing protections are not used.  CORB introduces a new XS-Leak technique since attackers may be able to observe the results of CORB. This can lead to a variety of different information leaks. However, in most cases this information leak has a lower impact than the data that could be leaked via speculative execution attacks.  References #    Cross-Origin Read Blocking for Web Developers, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':27,'href':'/docs/defenses/opt-in/coop/','title':"Cross-Origin-Opener-Policy",'section':"Opt-In Mechanisms",'content':"Getting access to a website\u0026rsquo;s window object is a common prerequisite for different XS-Leak techniques. Framing Protections can ensure that an attacker cannot use iframes to access the window object, but this does not stop an attacker from accessing it from an opened window through window.open(url) or window.opener references.\nExploiting XS-Leaks with window.open is generally seen as the least appealing option for an attacker because the user can see it happen in the open browser window. However, it\u0026rsquo;s usually the right technique when:\n A page sets Framing Protections A page sets Same-Site Cookies with Lax Mode (in contrast to the Strict mode, navigating a top-level window is allowed by the Lax mode)  To prevent other websites from gaining arbitrary window references to a page, applications can deploy Cross-Origin-Opener-Policy (COOP) 1 2.\nThere are three possible values for the COOP header. unsafe-none is the default value and is how websites behave if no value is set. same-origin is the strictest. If you set same-origin, then cross-origin websites cannot get access to your window object through opening new windows. If your application relies on using window.open to open another website and communicate with it, this will be blocked by same-origin. Instead, you can set same-origin-allow-popups which will allow your website to use window.open but does not allow other websites to use window.open against your application.\nIf possible, it is recommended to set same-origin. If you set same-origin-allow-popups be sure to review what websites you open with window.open and ensure that they are trusted.\nConsiderations #  Since COOP is an opt-in mechanism and a very recent one, it can easily be overlooked by developers and security engineers. Nonetheless, it’s important to highlight the importance of this defense mechanism as it is the only way to prevent attackers from exploiting XS-Leaks which makes use of window references returned by APIs like window.open (unless Same-Site Cookies in the Strict Mode can be widely deployed).\nDeployment #  Check out this web.dev article to learn more about the advantages of this protection and how to deploy it.\nReferences #    Cross-Origin-Opener-Policy response header (also known as COOP), link \u0026#x21a9;\u0026#xfe0e;\n Cross-Origin-Opener-Policy, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':28,'href':'/docs/defenses/opt-in/corp/','title':"Cross-Origin-Resource-Policy",'section':"Opt-In Mechanisms",'content':"Cross-Origin Resource Policy (CORP) is a web platform security feature that allows websites to prevent certain resources from being loaded by other origins. This protection complements CORB since it is an opt-in defense whereas CORB blocks some cross-origin reads by default. It is designed to protect against both speculative execution attacks and XS-Leaks by allowing developers to ensure that sensitive resources cannot end up in attacker controlled processes. Unlike CORB, this protection is enforced in the browser only if an application opts in to the protection. Applications can define which groups of origins (same-site, same-origin, cross-site) are allowed to read their resources.\nIf an application sets a certain resource CORP Header as same-site or same-origin, an attacker origin is incapable of reading that resource. This is a very strong and highly encouraged protection.\nCORP does not protect against navigational requests. This means that in browsers that do not support out-of-process iframes, a CORP protected resource may still end up in another origin\u0026rsquo;s process if framing protections are not used.  This mechanism introduced a new XS-Leak, which allows attackers to detect wether CORP was enforced in a certain request.  References #  "});index.add({'id':29,'href':'/docs/defenses/opt-in/fetch-metadata/','title':"Fetch Metadata",'section':"Opt-In Mechanisms",'content':"Fetch metadata headers are sent by browsers with HTTP requests. These headers provide context on how a request was initiated so that applications are able to make more informed decisions on how to respond to them. This allows servers to behave differently when they detect potential attacks (e.g. unexpected cross-origin requests)1. This can be very effective against cross-origin attacks like XSSI, XS-Leaks, Clickjacking, and CSRF if a strict policy is deployed on the server.\nIn the scenario of XS-Leaks, servers have the ability to know when a request was made cross-origin (e.g attacker origin) and can return a different response with no user data. This response has no utility to the attacker since it does not carry any information or state about the user. Fetch Metadata can also be used to block framing or even navigational requests.\nFetch metadata headers will be only attached to encrypted (HTTPS) requests for security reasons.  Fetch Metadata vs. Same-Site cookies #  Fetch metadata headers can be used to extend the protections of Same-Site cookies. While both Fetch Metadata headers and Same-Site cookies can be used to reject cross-site requests, Fetch Metadata can make more informed decisions based on factors like:\n Was the request same-origin or same-site? How was the request initiated? (e.g. fetch, script, top navigation) Was the request initiated by user interaction? Was the request initiated by the browser (e.g. entering the URL directly in the omnibox)?  This allows for a more precise deployment of protections in scenarios where Same-Site cookies could break service\u0026rsquo;s functionalities. One disadvantage of Fetch Metadata compared to Same-Site cookies is that the latter can also protect unencrypted requests (HTTP) while the former can\u0026rsquo;t.\nIn Defense sections we often assume that the service runs on HTTPS, and therefore, the protection can be applied.  Considerations #  Fetch metadata headers are a useful tool for a defense in depth strategy but should not be seen as a replacement for mechanisms such as Same-Site Cookies, COOP, or Framing Protections. Even though fetch metadata headers can be used to achieve similar results, it is a best practice to enforce these restrictions on the client side in addition to the server.\nThe usefulness of fetch metadata headers is dependent on the application coverage and deployment correctness.\nDeployment #  Check out this web.dev article to learn more about this protection, some different policies, and tips on how to deploy it.\nReferences #    Protect your resources from web attacks with Fetch Metadata, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':30,'href':'/docs/defenses/opt-in/xfo/','title':"Framing Protections",'section':"Opt-In Mechanisms",'content':"A considerable number of XS-Leaks relies on some properties of iframes. If an attacker is unable to embed the contents of a page as an iframe, frame, embed or object then the attack may no longer be possible. To mitigate XS-Leaks which rely on these objects, pages can forbid or select which origins can embed them. This is possible by using the X-Frame-Options Header or the CSP frame-ancestors directive.\nSince a website enforcing Framing Protections can\u0026rsquo;t be embedded from an attacker origin, the website is not rendered and the JavaScript does not run. Therefore, all of its subresources (images, JS, or CSS) are not retrieved by the browser.\nThe CSP frame-ancestors directive is the more modern way of enabling framing protections. But, it is not supported by Internet Explorer so in many cases it is recommended to use it in conjunction with the X-Frame-Options header.  Considerations #  This protection is very effective against XS-Leaks that rely on framing and can be easily implemented without breaking the vast majority of applications. This mechanism not only protects from some XS-Leaks but also protects from attacks like clickjacking.\nDeployment #  Deploying framing protections is usually straightforward as many applications are not meant to be embedded cross-origin in an iframe. Check out this web.dev article to learn more about the advantages of this header.\n"});index.add({'id':31,'href':'/docs/defenses/secure-defaults/partitioned-cache/','title':"Partitioned HTTP Cache",'section':"Secure Defaults",'content':"In order to defend against cache probing attacks, browsers are actively working on implementing a partitioned HTTP cache that would in essence ensure each website has a distinct cache. Since cache probing relies on the fact that browsers' HTTP cache is shared across every website, this can defend against many cache probing techniques. This is done by using tuples (either (top-frame-site, resource-url) or (top-frame-site, framing-site, resource-url)) as the cache keys to ensure the cache is partitioned by the requesting site. This makes it more challenging for attackers to interact with the cached contents of different sites 1 2 3. Safari currently ships a partitioned cache 4 while Chrome and Firefox are both actively working on implementing this 5 6.\nIn browsers that don\u0026rsquo;t use partitioned caches, there are other defenses that applications can deploy to defend against cache probing techniques. Pages can also be designed to require some level of user interaction in order to defend against cache probing attacks.  Other Relevant Projects #  WebKit Tracking Prevention Technologies #  Safari implements a partitioned HTTP Cache using (top-frame-site, resource URL) as the cache key. This is part of WebKit\u0026rsquo;s larger Tracking Prevention project.\nFirefox First Party Isolation #  First Party Isolation is a Browser Extension for Firefox which restricts access to cookies and persistent data (e.g cache) per domain. This is opt-in on the part of the user.\nConsiderations #  Partitioned HTTP caches are a promising security feature that will eventually land in browsers. These partitioning strategies will mitigate most of the XS-Leak techniques that leverage browser caches. In the future, partitioned caches might be extended to other browser resources which could help mitigate other XS-Leak techniques like the Socket Exhaustion XS-Leak.\nReferences #    Double-keyed HTTP cache, link \u0026#x21a9;\u0026#xfe0e;\n Explainer - Partition the HTTP Cache, link \u0026#x21a9;\u0026#xfe0e;\n Client-Side Storage Partitioning, link \u0026#x21a9;\u0026#xfe0e;\n Optionally partition cache to prevent using cache for tracking (Webkit), link \u0026#x21a9;\u0026#xfe0e;\n Split Disk Cache Meta Bug (Blink), link \u0026#x21a9;\u0026#xfe0e;\n Top-level site partitioning (Gecko), link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':32,'href':'/docs/attacks/experiments/portals/','title':"Portals",'section':"Experiments",'content':"Portals are a new feature of the web similar to iframes with more emphasis on speed and user experience. The portal element is only available on Chromium-based browsers under a preference flag. The corresponding specification is still under active discussion.\nUnfortunately, some research over this new feature found critical issues, including new XS-Leaks 1.\nID Leaks #  Portals can be abused as an alternative for the ID Attribute XS-Leak. If the website sets framing protections, the same technique can be applied using the portal element instead 2.\nReferences #    Security analysis of \u0026lt;portal\u0026gt; element, link \u0026#x21a9;\u0026#xfe0e;\n Detecting IDs using Portal, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':33,'href':'/docs/defenses/opt-in/same-site-cookies/','title':"Same-Site Cookies",'section':"Opt-In Mechanisms",'content':"Same-Site cookies are one of the most impactful modern security mechanisms for fixing security issues that involve cross-site requests. This mechanism allows applications to make browsers only include cookies in requests that are issued same-site 1. This type of cookies has three modes: None, Lax, and Strict.\nSame-Site Cookie Modes #  None disables all protections and restores the old behavior of cookies. This mode is not recommended.\nThe None attribute must come with the Secure flag 1.\n  SameSite cookies explained, link \u0026#x21a9;\u0026#xfe0e;\n    Strict causes the browser to not include cookies in any cross-site requests. This means \u0026lt;script src=\u0026quot;example.com/resource\u0026quot;\u0026gt;, \u0026lt;img src=\u0026quot;example.com/resource\u0026quot;\u0026gt;, fetch(), and XHR will all make requests without the same-site Strict cookies attached. Even if the user clicks on a link to example.com/resource then their cookies will not be included.\nThe only difference between Lax and Strict is that Lax mode allows cookies to be added to requests triggered by top-level navigations. This makes Lax cookies much easier to deploy since they won\u0026rsquo;t break incoming links to your application. Unfortunately, an attacker can trigger a top-level navigation via window.open that allows the attacker to maintain a reference to the window object.\nConsiderations #  Strict cookies provide the strongest security guarantees, but it can be very difficult to deploy Strict same-site cookies in an existing application.\nSame-Site cookies are not bulletproof 2 nor they can fix everything. To complete the defense strategy against XS-Leaks users should consider implementing other protections that complement same-site cookies. For example, COOP can prevent an attacker from controlling pages using a window reference even if Lax Same-Site Cookies are used.\nDeployment #  Anyone interested in deploying this mechanism in web applications should take a careful look at this web.dev article.\nReferences #    SameSite cookies explained, link \u0026#x21a9;\u0026#xfe0e;\n Bypass SameSite Cookies Default to Lax and get CSRF, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':34,'href':'/docs/attacks/experiments/scroll-to-text-fragment/','title':"Scroll to Text Fragment",'section':"Experiments",'content':"Scroll to Text Fragment (STTF) is a new web platform feature that allows users to create a link to any part of a web page text. The fragment #:~:text= carries a text snippet that is highlighted and brought into the viewport by the browser. This feature can introduce a new XS-Leak if attackers are able to detect when this behavior occurs. This issue is very similar to the Scroll to CSS Selector XS-Leak.\nExpected \u0026amp; Discussed Issues #  In early discussions for the specification of this feature it was shown that several XS-Leaks could be introduced with a naïve implementation 1. The specification considers various attack scenarios 2, as does some research from Google 3. One possible XS-Leak browsers need to be aware of when implementing this feature is:\n An attacker can, by embedding a page as an iframe, detect whether the page scrolled to the text by listening to the onblur of the parent document. This approach is similar to the ID Attribute XS-Leak. This scenario is mitigated in the Chrome implementation 4 as it only allows the fragment navigation to occur in top-level navigations.  Current Issues #  These XS-Leaks require some type of markup injection on the target page.  During the development process of STTF new attacks and tricks to detect a fragment navigation were found. Some of them still work:\n A web page that embeds an attacker-controlled iframe might allow the attacker to determine whether a scroll to the text has occurred. This can be done using the IntersectionObserver API 5 2 3. If a page contains images with Lazy Loading an attacker might known if a fragment navigation that included an image occurred by checking whether it was cached in the browser. This occurs because Lazy Loading images are only fetched (and cached) when they appear in the viewport.  Scroll to Text Fragment is only available in Chrome. Its draft specification is under active discussion.  Scroll to Text Fragment XS-Leaks allow attackers to extract 1 bit of information at a time as it\u0026rsquo;s only possible to observe whether a group of words is present in a page. This is because STTF matching is based on words, so attackers won\u0026rsquo;t be able to leak information character by character.  Why is this a problem? #  Attackers can abuse STTF to leak private information about the user that is displayed on a web page.\nCase Scenarios #   A user is logged in to their National Health System website, where it is possible to access information about the user\u0026rsquo;s past diseases and health problems. An attacker can lure the user to one of their pages and use STTF to possibly infer the user\u0026rsquo;s health details. For example an attacker would find out if the victim suffers from a disease if they detect a page scroll when searching for that disease name.  Defense #     Attack Alternative Same-Site Cookies Fetch Metadata COOP Framing Protections     IntersectionObserver (iframes) ❌ ❌ ❌ ❌   Lazy Loading ✔️ ✔️ ❌ ❌    References #    Privacy concerns with proposal through inducing network requests, link \u0026#x21a9;\u0026#xfe0e;\n Text Fragments - Security and Privacy, link \u0026#x21a9;\u0026#xfe0e;\n Scroll-to-text Fragment Navigation - Security Issues, link \u0026#x21a9;\u0026#xfe0e;\n Boldly link where no one has linked before: Text Fragments, link \u0026#x21a9;\u0026#xfe0e;\n Possible side-channel information leak using IntersectionObserver, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':35,'href':'/docs/attacks/historical/stateful-browser-features/','title':"Stateful Browser Features",'section':"Historical",'content':"Some browser features/extensions change the way requests are processed depending on certain website states generated by the browser. Attackers can sometimes observe the whole process and mess with the browser, triggering actions that produce side-effects on those states.\nWebKit - ITP #  Intelligent Tracking Prevention (ITP) is a privacy feature part of WebKit Tracking Prevention technologies. It’s a conjunction of several features to prevent a website from tracking a user under a third-party context. Unfortunately, the initial design introduced a new XS-Leak 1, allowing attackers to abuse the states implicitly created by ITP to classify websites as trackers.\nRoot Cause #  To classify whether a website has tracking capabilities, ITP collects statistics on resource loads as well as user interactions in websites such as clicks, taps, or text entries. Based on the classification of these statistics, ITP gives a strike to a website if it is believed to have tracking capabilities. After 3 strikes a website is put on a deny list and is treated differently by the browser in future requests.\nIssues #  One of the issues of ITP is that attackers can manipulate it to arbitrarily enforce certain behaviors. For example, one could force ITP to give a strike to a domain and check if the domain entered the deny list. This could be levered in different ways, for example:\n Leaking the user\u0026rsquo;s browsing habits based off of how many strikes are necessary for a domain to enter the deny list Using the deny list to implement an XS-Search attack against a page that includes cross-site resources only when results are present  Fix #  To fix the issue, instead of relying on classifications, ITP now considers every site as a \u0026ldquo;tracking\u0026rdquo; one by default. This removes the implicit states which allowed attackers to detect certain ITP behaviors.\nReferences #    Information Leaks via Safari’s Intelligent Tracking Prevention, link \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':36,'href':'/docs/defenses/design-protections/subresource-protections/','title':"Subresource Protections",'section':"Application Design",'content':"The fundamental idea behind designing protections for subresources is that subresources cannot be targeted by XS-Leaks if the attacker cannot make them return any user data. If implemented correctly, this approach can be a very strong defense, though it is likely to be tough to implement and could negatively impact the user experience.\nIt can be very effective to deploy this approach on any specific resources that are known to be especially sensitive to XS-Leaks. But, due to the challenges of deploying this protection universally, applications are encouraged to deploy opt-in web platform security features as the default approach.  Token-Based Protections #  A strong protection for subresources can be achieved by including a user-specific token in every request. This protects against most XS-Leak techniques if implemented correctly. The idea is that in order to verify a request for a resource as being legitimate, a token must be included. This token must be provided to the client in a way that prevents an attacker from including it in their own requests.\nSuppose there is a search bar in an application.\n When the user loads the main page, the server includes a secure token somewhere in the body of the page. When the user searches for something, a request is made to /search?query=\u0026lt;QUERY\u0026gt;\u0026amp;token=\u0026lt;SECURE_TOKEN\u0026gt;. The backend verifies that the provided token is valid for the current user. If it is not valid, the request is rejected.  In this scenario, there is no way for an attacker to trigger any requests to the endpoint because they cannot obtain a valid token for a given user. Note that this relies on it not being possible for an attacker to obtain or forge a token for other users. If they can do so, this approach is not effective.\n This style of protection can be applied to:\n Authenticated subresources such as API endpoints or regular authenticated URLs. While tokens can be used in this case, security mitigations like Same-Site Cookies may be easier to deploy at scale. Unauthenticated subresources such as images can use this protection to prevent some types of Cache Probing Attacks. While this does work, see Cache Protections for other strategies to defend against cache probing attacks.  Implementing token-based protections might break the ability of users to save or share links (e.g. bookmarks).  User Consent #  Another strong defense is to require user interaction before returning any sensitive data. This ensures that sensitive endpoints cannot be included via script or img tags. For example, Facebook requires user confirmation before viewing search results or private messages. Since attackers cannot simulate this user interaction, they are unable to leak the contents of the search results.\nThis can be a very useful way of protecting especially sensitive endpoints, but note once again that this is likely to be time-consuming to implement.\n"});})();